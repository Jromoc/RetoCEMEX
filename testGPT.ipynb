{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from annoy import AnnoyIndex\n",
    "import glob\n",
    "import os\n",
    "import fitz\n",
    "from pymongo import MongoClient\n",
    "from urllib.parse import quote_plus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = quote_plus(\"a01197772\")\n",
    "password = quote_plus(\"sWtcW2001%&\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONGODB_URI = f\"mongodb+srv://{username}:{password}@cluster0.2cpkshg.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(MONGODB_URI)\n",
    "db = client['cemex_proyecto']\n",
    "collection = db['embedded_documents']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de MongoDB\n",
    "#MONGODB_URI = \"mongodb+srv://a01197772:sWtcW2001%&@cluster0.2cpkshg.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"  # Reemplaza con tu URI de MongoDB Atlas\n",
    "#client = MongoClient(MONGODB_URI)\n",
    "#db = client['cemex_proyecto'] # cemex_proyecto\n",
    "#collection = db['embedded_documents'] # embedded_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (294 > 77). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al generar el embedding del archivo C:/Users/josee/OneDrive/Documents/8vo Semestre/Reto/RetoCEMEX/PDF\\Ejemplo1.pdf: The size of tensor a (294) must match the size of tensor b (77) at non-singleton dimension 1\n",
      "Error al generar el embedding del archivo C:/Users/josee/OneDrive/Documents/8vo Semestre/Reto/RetoCEMEX/PDF\\Ejemplo2.pdf: The size of tensor a (287) must match the size of tensor b (77) at non-singleton dimension 1\n",
      "Error al generar el embedding del archivo C:/Users/josee/OneDrive/Documents/8vo Semestre/Reto/RetoCEMEX/PDF\\Ejemplo3.pdf: The size of tensor a (209) must match the size of tensor b (77) at non-singleton dimension 1\n"
     ]
    }
   ],
   "source": [
    "# Ruta al directorio que contiene los archivos PDF\n",
    "pdf_dir = \"C:/Users/josee/OneDrive/Documents/8vo Semestre/Reto/RetoCEMEX/PDF\"\n",
    "\n",
    "# Cargar el modelo SentenceTransformer\n",
    "model_name = \"clip-ViT-L-14\"\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# Función para extraer texto de un archivo PDF\n",
    "def extraer_texto_de_pdf(pdf_path, max_length=512):\n",
    "    texto = \"\"\n",
    "    try:\n",
    "        with fitz.open(pdf_path) as archivo_pdf:\n",
    "            for num_pagina in range(len(archivo_pdf)):\n",
    "                pagina = archivo_pdf[num_pagina]\n",
    "                texto_pagina = pagina.get_text()\n",
    "                # Truncar el texto de la página si es necesario\n",
    "                if len(texto) + len(texto_pagina) > max_length:\n",
    "                    texto_pagina = texto_pagina[:max_length - len(texto)]\n",
    "                texto += texto_pagina\n",
    "    except Exception as e:\n",
    "        print(f\"Error al leer el archivo PDF {pdf_path}: {e}\")\n",
    "    return texto\n",
    "\n",
    "# Función para dividir texto en fragmentos más pequeños\n",
    "def dividir_texto_en_fragmentos(texto, max_length=77):\n",
    "    palabras = texto.split()\n",
    "    fragmentos = []\n",
    "    for i in range(0, len(palabras), max_length):\n",
    "        fragmento = ' '.join(palabras[i:i + max_length])\n",
    "        fragmentos.append(fragmento)\n",
    "    return fragmentos\n",
    "\n",
    "# Función para almacenar embeddings en MongoDB\n",
    "def almacenar_embeddings_en_mongodb(archivo, embedding):\n",
    "    try:\n",
    "        documento = {\n",
    "            \"archivo\": archivo,\n",
    "            \"embedding\": embedding.tolist()  # Convertir el embedding a lista para almacenar en MongoDB\n",
    "        }\n",
    "        collection.insert_one(documento)\n",
    "        print(f\"Embeddings del archivo {archivo} almacenados en MongoDB.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al almacenar embeddings en MongoDB: {e}\")\n",
    "\n",
    "# Procesar archivos PDF y almacenar embeddings\n",
    "def procesar_y_almacenar_embeddings():\n",
    "    archivos = glob.glob(os.path.join(pdf_dir, \"*.pdf\"))\n",
    "    for archivo in archivos:\n",
    "        texto = extraer_texto_de_pdf(archivo)\n",
    "        if texto:\n",
    "            try:\n",
    "                fragmentos = dividir_texto_en_fragmentos(texto)\n",
    "                embeddings = model.encode(fragmentos)\n",
    "                embedding_promediado = np.mean(embeddings, axis=0)\n",
    "                almacenar_embeddings_en_mongodb(archivo, embedding_promediado)\n",
    "            except Exception as e:\n",
    "                print(f\"Error al generar el embedding del archivo {archivo}: {e}\")\n",
    "\n",
    "# Función para buscar en los archivos PDF\n",
    "def buscar_en_archivos_pdf(consulta):\n",
    "    archivos = glob.glob(os.path.join(pdf_dir, \"*.pdf\"))\n",
    "\n",
    "    # Indexar archivos PDF\n",
    "    annoy_index = AnnoyIndex(1024, metric='angular')\n",
    "    for idx, archivo in enumerate(archivos):\n",
    "        texto = extraer_texto_de_pdf(archivo)\n",
    "        fragmentos = dividir_texto_en_fragmentos(texto)\n",
    "        embeddings = model.encode(fragmentos)\n",
    "        embedding_promediado = np.mean(embeddings, axis=0)\n",
    "        annoy_index.add_item(idx, embedding_promediado)\n",
    "    annoy_index.build(10)\n",
    "\n",
    "    # Codificar la consulta y encontrar archivos PDF similares\n",
    "    incrustacion_consulta = model.encode([consulta])[0]\n",
    "    indices_mas_cercanos, distancias_mas_cercanas = annoy_index.get_nns_by_vector(incrustacion_consulta, 5, include_distances=True)\n",
    "\n",
    "    # Mostrar o procesar los archivos PDF más cercanos\n",
    "    resultados = []\n",
    "    for idx, distancia in zip(indices_mas_cercanos, distancias_mas_cercanas):\n",
    "        resultados.append((archivos[idx], distancia))\n",
    "    return resultados\n",
    "\n",
    "# Ejecutar el proceso de almacenamiento de embeddings\n",
    "procesar_y_almacenar_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (294 > 77). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al generar el embedding del archivo C:/Users/josee/OneDrive/Documents/8vo Semestre/Reto/RetoCEMEX/PDF\\Ejemplo1.pdf: The size of tensor a (294) must match the size of tensor b (77) at non-singleton dimension 1\n",
      "Error al generar el embedding del archivo C:/Users/josee/OneDrive/Documents/8vo Semestre/Reto/RetoCEMEX/PDF\\Ejemplo2.pdf: The size of tensor a (287) must match the size of tensor b (77) at non-singleton dimension 1\n",
      "Error al generar el embedding del archivo C:/Users/josee/OneDrive/Documents/8vo Semestre/Reto/RetoCEMEX/PDF\\Ejemplo3.pdf: The size of tensor a (209) must match the size of tensor b (77) at non-singleton dimension 1\n"
     ]
    }
   ],
   "source": [
    "# Ruta al directorio que contiene los archivos PDF\n",
    "pdf_dir = \"C:/Users/josee/OneDrive/Documents/8vo Semestre/Reto/RetoCEMEX/PDF\"\n",
    "\n",
    "# Cargar el modelo SentenceTransformer\n",
    "model_name = \"clip-ViT-L-14\"\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# Función para extraer texto de un archivo PDF\n",
    "def extraer_texto_de_pdf(pdf_path, max_length=512):\n",
    "    texto = \"\"\n",
    "    try:\n",
    "        with fitz.open(pdf_path) as archivo_pdf:\n",
    "            for num_pagina in range(len(archivo_pdf)):\n",
    "                pagina = archivo_pdf[num_pagina]\n",
    "                texto_pagina = pagina.get_text()\n",
    "                # Truncar el texto de la página si es necesario\n",
    "                if len(texto) + len(texto_pagina) > max_length:\n",
    "                    texto_pagina = texto_pagina[:max_length - len(texto)]\n",
    "                texto += texto_pagina\n",
    "    except Exception as e:\n",
    "        print(f\"Error al leer el archivo PDF {pdf_path}: {e}\")\n",
    "    return texto\n",
    "\n",
    "# Función para dividir texto en fragmentos más pequeños\n",
    "def dividir_texto_en_fragmentos(texto, max_length=77):\n",
    "    palabras = texto.split()\n",
    "    fragmentos = []\n",
    "    for i in range(0, len(palabras), max_length):\n",
    "        fragmento = ' '.join(palabras[i:i + max_length])\n",
    "        fragmentos.append(fragmento)\n",
    "    return fragmentos\n",
    "\n",
    "# Función para almacenar embeddings en MongoDB\n",
    "def almacenar_embeddings_en_mongodb(archivo, embedding):\n",
    "    try:\n",
    "        documento = {\n",
    "            \"archivo\": archivo,\n",
    "            \"embedding\": embedding.tolist()  # Convertir el embedding a lista para almacenar en MongoDB\n",
    "        }\n",
    "        collection.insert_one(documento)\n",
    "        print(f\"Embeddings del archivo {archivo} almacenados en MongoDB.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al almacenar embeddings en MongoDB: {e}\")\n",
    "\n",
    "# Procesar archivos PDF y almacenar embeddings\n",
    "def procesar_y_almacenar_embeddings():\n",
    "    archivos = glob.glob(os.path.join(pdf_dir, \"*.pdf\"))\n",
    "    for archivo in archivos:\n",
    "        texto = extraer_texto_de_pdf(archivo)\n",
    "        if texto:\n",
    "            try:\n",
    "                fragmentos = dividir_texto_en_fragmentos(texto)\n",
    "                embeddings = model.encode(fragmentos)\n",
    "                embedding_promediado = np.mean(embeddings, axis=0)\n",
    "                almacenar_embeddings_en_mongodb(archivo, embedding_promediado)\n",
    "            except Exception as e:\n",
    "                print(f\"Error al generar el embedding del archivo {archivo}: {e}\")\n",
    "\n",
    "# Función para buscar en los archivos PDF\n",
    "def buscar_en_archivos_pdf(consulta):\n",
    "    archivos = glob.glob(os.path.join(pdf_dir, \"*.pdf\"))\n",
    "\n",
    "    # Indexar archivos PDF\n",
    "    annoy_index = AnnoyIndex(1024, metric='angular')\n",
    "    for idx, archivo in enumerate(archivos):\n",
    "        texto = extraer_texto_de_pdf(archivo)\n",
    "        fragmentos = dividir_texto_en_fragmentos(texto)\n",
    "        embeddings = model.encode(fragmentos)\n",
    "        embedding_promediado = np.mean(embeddings, axis=0)\n",
    "        annoy_index.add_item(idx, embedding_promediado)\n",
    "    annoy_index.build(10)\n",
    "\n",
    "    # Codificar la consulta y encontrar archivos PDF similares\n",
    "    incrustacion_consulta = model.encode([consulta])[0]\n",
    "    indices_mas_cercanos, distancias_mas_cercanas = annoy_index.get_nns_by_vector(incrustacion_consulta, 5, include_distances=True)\n",
    "\n",
    "    # Mostrar o procesar los archivos PDF más cercanos\n",
    "    resultados = []\n",
    "    for idx, distancia in zip(indices_mas_cercanos, distancias_mas_cercanas):\n",
    "        resultados.append((archivos[idx], distancia))\n",
    "    return resultados\n",
    "\n",
    "# Ejecutar el proceso de almacenamiento de embeddings\n",
    "procesar_y_almacenar_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "consulta = input(\"Palabra Clave sobre lo que busca: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (294) must match the size of tensor b (77) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Consulta de búsqueda\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#consulta = \"EJEMPLO DE FACTURA SIMPLE\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Realizar la búsqueda\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m resultados \u001b[38;5;241m=\u001b[39m \u001b[43mbuscar_en_archivos_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconsulta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Mostrar resultados\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m resultado \u001b[38;5;129;01min\u001b[39;00m resultados:\n",
      "Cell \u001b[1;32mIn[17], line 56\u001b[0m, in \u001b[0;36mbuscar_en_archivos_pdf\u001b[1;34m(consulta)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, archivo \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(archivos):\n\u001b[0;32m     55\u001b[0m     texto \u001b[38;5;241m=\u001b[39m extraer_texto_de_pdf(archivo)\n\u001b[1;32m---> 56\u001b[0m     incrustacion \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtexto\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     57\u001b[0m     annoy_index\u001b[38;5;241m.\u001b[39madd_item(idx, incrustacion)\n\u001b[0;32m     58\u001b[0m annoy_index\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\josee\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:371\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[1;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[0;32m    368\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 371\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    372\u001b[0m     out_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m truncate_embeddings(\n\u001b[0;32m    373\u001b[0m         out_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtruncate_dim\n\u001b[0;32m    374\u001b[0m     )\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_value \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\josee\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\josee\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\josee\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\josee\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\models\\CLIPModel.py:30\u001b[0m, in \u001b[0;36mCLIPModel.forward\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     27\u001b[0m     image_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mvisual_projection(vision_outputs[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m---> 30\u001b[0m     text_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mposition_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_attentions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_hidden_states\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     text_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtext_projection(text_outputs[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     39\u001b[0m sentence_embedding \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\josee\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\josee\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\josee\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\clip\\modeling_clip.py:697\u001b[0m, in \u001b[0;36mCLIPTextTransformer.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    694\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m    695\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, input_shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m--> 697\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[38;5;66;03m# CLIP's text model uses causal mask, prepare it here.\u001b[39;00m\n\u001b[0;32m    700\u001b[0m \u001b[38;5;66;03m# https://github.com/openai/CLIP/blob/cfcffb90e69f37bf2ff1e988237a0fbe41f33c04/clip/model.py#L324\u001b[39;00m\n\u001b[0;32m    701\u001b[0m causal_attention_mask \u001b[38;5;241m=\u001b[39m _create_4d_causal_attention_mask(\n\u001b[0;32m    702\u001b[0m     input_shape, hidden_states\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mhidden_states\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m    703\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\josee\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\josee\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\josee\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\clip\\modeling_clip.py:225\u001b[0m, in \u001b[0;36mCLIPTextEmbeddings.forward\u001b[1;34m(self, input_ids, position_ids, inputs_embeds)\u001b[0m\n\u001b[0;32m    222\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_embedding(input_ids)\n\u001b[0;32m    224\u001b[0m position_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding(position_ids)\n\u001b[1;32m--> 225\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43minputs_embeds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mposition_embeddings\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (294) must match the size of tensor b (77) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# Consulta de búsqueda\n",
    "#consulta = \"EJEMPLO DE FACTURA SIMPLE\"\n",
    "\n",
    "resultados = buscar_en_archivos_pdf(consulta)\n",
    "for resultado in resultados:\n",
    "    print(resultado)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
